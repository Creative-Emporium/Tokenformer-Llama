batch_size: 32
d_model: 64
data_path: /content/tinyshakespeare.txt
dataset_config: wikitext-2-raw-v1
dataset_name: wikitext
dropout: 0.1
expansion_factor: 4
gqa_num_groups: 2
gradient_accumulation_steps: 5
init_model_size: 1
learning_rate: 0.0001
local_dataset: true
max_seq_len: 128
n_layers: 4
num_epochs: 3
num_params: 16.753152
online_dataset: false
save_path: trained_model
scale_factor: 1
scale_model: false
weight_decay: 0.01
